{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question & Answering With AI\n",
    "\n",
    "### 1. Basic Question & Answering\n",
    "\n",
    "Let's first install the required libraries and load up our packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (0.0.351)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain) (0.0.4)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain) (0.1.1)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.70 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain) (0.0.71)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from openai) (4.2.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: sniffio in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from openai) (1.3.0)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
      "Requirement already satisfied: colorama in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-1.5.0-py3-none-any.whl (223 kB)\n",
      "Using cached httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.5.0 tqdm-4.66.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.5.2-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2023.10.3-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\workspace\\openai\\summary-extension\\.conda\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
      "Using cached tiktoken-0.5.2-cp311-cp311-win_amd64.whl (786 kB)\n",
      "Using cached regex-2023.10.3-cp311-cp311-win_amd64.whl (269 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.10.3 tiktoken-0.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://devsquad-eastus-2.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "api_key=os.environ['OPENAI_API_KEY']\n",
    "base_url=os.environ['OPENAI_BASE_URL']\n",
    "\n",
    "print(base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries of Short Text\n",
    "\n",
    "For summaries of short texts, the method is straightforward, in fact you don't need to do anything fancy other than simple prompting with instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=base_url, \n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "Please provide a summary of the following text:\n",
    "\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's test it with a small story:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "Once upon a time, in a small village nestled between the mountains and the sea, lived a mighty dragon and a wise princess. The dragon, known for its fiery breath, was feared by all. The princess, on the other hand, was loved for her kindness and wisdom.\n",
    "The princess was deeply concerned about the changing climate. She noticed the winters becoming harsher, the summers hotter, and the crops failing. She realized that the dragon’s fire, used to keep the villagers warm during the cold winters, was contributing to the rising temperatures.\n",
    "She decided to have a conversation with the dragon. “Dear friend,” she began, “Our village is suffering because of the changing climate. The heat from your fire is making the summers unbearable and affecting our crops. We need to find a solution.”\n",
    "The dragon, who cared for the village as much as the princess, agreed. They decided to limit the use of the dragon’s fire to only the coldest days of winter. The dragon also helped the villagers build energy-efficient homes to stay warm.\n",
    "The princess didn’t stop there. She educated the villagers about the importance of sustainable living. They started planting more trees, recycling, and using renewable energy sources.\n",
    "Over time, the village became a model of sustainability. The dragon and the princess showed everyone that with understanding, cooperation, and sustainable practices, it’s possible to combat climate change. And so, they continued to live in harmony with nature, proving that even in a story of a princess and a dragon, there’s room for real-world issues like climate change.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please provide a summary of the following text:\n",
      "\n",
      "\n",
      "Once upon a time, in a small village nestled between the mountains and the sea, lived a mighty dragon and a wise princess. The dragon, known for its fiery breath, was feared by all. The princess, on the other hand, was loved for her kindness and wisdom.\n",
      "The princess was deeply concerned about the changing climate. She noticed the winters becoming harsher, the summers hotter, and the crops failing. She realized that the dragon’s fire, used to keep the villagers warm during the cold winters, was contributing to the rising temperatures.\n",
      "She decided to have a conversation with the dragon. “Dear friend,” she began, “Our village is suffering because of the changing climate. The heat from your fire is making the summers unbearable and affecting our crops. We need to find a solution.”\n",
      "The dragon, who cared for the village as much as the princess, agreed. They decided to limit the use of the dragon’s fire to only the coldest days of winter. The dragon also helped the villagers build energy-efficient homes to stay warm.\n",
      "The princess didn’t stop there. She educated the villagers about the importance of sustainable living. They started planting more trees, recycling, and using renewable energy sources.\n",
      "Over time, the village became a model of sustainability. The dragon and the princess showed everyone that with understanding, cooperation, and sustainable practices, it’s possible to combat climate change. And so, they continued to live in harmony with nature, proving that even in a story of a princess and a dragon, there’s room for real-world issues like climate change.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_prompt = prompt.format(text=story)\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's use our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a small village, a mighty dragon and a wise princess lived among the residents. The princess noticed the adverse effects of climate change, such as extreme weather and failing crops, and realized the dragon's fire was contributing to the problem. She approached the dragon, and together they agreed to limit the use of its fire to the coldest days and to help villagers build energy-efficient homes. The princess also led the village in adopting sustainable practices, such as planting trees, recycling, and using renewable energy. Over time, the village became a model of sustainability, demonstrating that cooperation and sustainable living can address climate change, with the dragon and princess living in harmony with nature and highlighting the relevance of environmental issues in their story.\n"
     ]
    }
   ],
   "source": [
    "message = HumanMessage(content=final_prompt)\n",
    "output = llm([message])\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method works fine, but for longer text, it can become a pain to manage and you'll run into token limits. Luckily LangChain has out of the box support for different methods to summarize via their `load_summarize_chain`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries of Longer Text\n",
    "\n",
    "Note: This method will also work for short text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load your data\n",
    "\n",
    "We need to define a function to extract the article part of it using `BeautifulSoup4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def extract_article(content: BeautifulSoup) -> str:\n",
    "    # Find all 'article' elements in the BeautifulSoup object\n",
    "    article_elements = content.find_all(\"article\")\n",
    "\n",
    "    return str(article_elements.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll load our PDF text into a variable. The `WebBaseLoader` will convert our text for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://www.newyorker.com/news/letter-from-the-uk/the-collateral-damage-of-queen-elizabeths-glorious-reign\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many tokens this would use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tokens in the message is 4769.\n"
     ]
    }
   ],
   "source": [
    "num_tokens = llm.get_num_tokens(data[0].page_content)\n",
    "print(f\"The number of tokens in the message is {num_tokens}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many documents and characters we have in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 documents in your data\n",
      "There are 21761 characters in your first document\n"
     ]
    }
   ],
   "source": [
    "print(f'You have {len(data)} documents in your data')\n",
    "print(f'There are {len(data[0].page_content)} characters in your first document')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunk your data up into smaller documents\n",
    "Let's split into smaller chunks and assume is too big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=500)\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 3 documents in your data\n"
     ]
    }
   ],
   "source": [
    "print(f'You have {len(docs)} documents in your data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Collateral Damage of Queen Elizabeth’s Glorious Reign | The New YorkerSkip to main contentNewsletterStory SavedTo revisit this article, select My Account, then View saved storiesClose AlertSign InSearchSearchThe Latest2023 in ReviewNewsBooks & CultureFiction & PoetryHumor & CartoonsMagazinePuzzles & GamesVideoPodcastsGoings OnShopOpen Navigation MenuMenuStory SavedFind anything you save across the site in your account Close AlertLetter from the U.K.The Collateral Damage of Queen Elizabeth’s \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the `load_summarize_chain` with `map_reduce` to summarize our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "chain = load_summarize_chain(llm=llm, chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam Knight's article in The New Yorker, based on insights from Tina Brown's \"The Palace Papers,\" examines the personal challenges faced by the British Royal Family during Queen Elizabeth II's reign. The monarchy is depicted as a system where the Queen holds authority, while other royals are confined to ceremonial roles, leading to a sense of purposelessness and personal struggles. The Queen's children and grandchildren have had varied experiences, with some facing scandals and others seeking a life away from royal duties. The article touches on the future of the monarchy, highlighting Prince Charles's environmental activism and the potential stability offered by Prince William and Catherine's family. It also addresses broader issues such as calls for reparations and the possibility of countries distancing themselves from the monarchy. The summary concludes by mentioning The New Yorker's diverse content and Sam Knight's credentials as a staff writer and author.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
